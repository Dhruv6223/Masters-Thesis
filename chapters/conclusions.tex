\chapter{Conclusion}

In this thesis, the challenges and few solutions were discussed in context of \acrshort{ml}, \acrshort{nlp}, document processing and development of a deployment workflow in order to serve the \acrshort{ml} service to end-users as SaaS. The first challenge was to deal with a different type, languages and layout information of any documents. We used \acrshort{ocr} to convert the document format into machine readable format in order to extract information such as words and their location into a document. However, with different region the layout and language of a document changes. Therefore, we chose to take advantage of \acrshort{ml} techniques called \acrlong{nlp} for the language of these documents. For the layout information, we used the model and method describe in Chapter Methods, which made possible to deal with the information such as language and layout from a documents in order to classify content on the whole document. 

In order to serve the model as a service, our main concern was to have a model that is performing good in German language and available for end-user in a way that is scalable, secure and faster in terms of development and over all performance. We used the model \acrshort{lilt}, originally proposed by \cite{wang-etal-2022-lilt}. According to author \cite{wang-etal-2022-lilt} \acrshort{lilt} is a \acrlong{lilt} and it can learn the language and layout knowledge from monolingual structured documents and generalize it to deal with multilingual documents, It can be pre-trained in one language and further fine-tune in any languages, this functionality makes it multi-lingual since regardless of the language \acrshort{lilt} has been pre-trained, it can be fine-tune using same methods in any language. Originally \acrshort{lilt} was pre-trained on English language documents which we further fine-tuned for token classification task using German language documents in order to get the better performance on German language documents. We chose different combination of \acrshort{lilt} with text-based models and fine-tuned for 30 and 100 epoch in order to compare the overall performance of different combinations. We then evaluate the models for German language documents in order to choose the best model for the deployment. 

