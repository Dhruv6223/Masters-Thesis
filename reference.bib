

@inproceedings{wang-etal-2022-lilt,
    title = "{L}i{LT}: A Simple yet Effective Language-Independent Layout Transformer for Structured Document Understanding",
    author={Wang, Jiapeng and Jin, Lianwen and Ding, Kai},
    booktitle = "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = may,
    year = "2022",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.acl-long.534",
    doi = "10.18653/v1/2022.acl-long.534",
    pages = "7747--7757",
}

@inproceedings{johri2021natural,
  title={Natural language processing: History, evolution, application, and future work},
  author={Johri, Prashant and Khatri, Sunil K and Al-Taani, Ahmad T and Sabharwal, Munish and Suvanov, Shakhzod and Kumar, Avneesh},
  booktitle={Proceedings of 3rd International Conference on Computing Informatics and Networks: ICCIN 2020},
  pages={365--375},
  year={2021},
  organization={Springer}
}

@article{spruitsupervisors,
  title={Supervisors: Prof. dr. MR Spruit \& Dr. MR Haas},
  author={Spruit, MR}
}


@article{brown1990statistical,
  title={A statistical approach to machine translation},
  author={Brown, Peter F and Cocke, John and Della Pietra, Stephen A and Della Pietra, Vincent J and Jelinek, Frederick and Lafferty, John and Mercer, Robert L and Roossin, Paul S},
  journal={Computational linguistics},
  volume={16},
  number={2},
  pages={79--85},
  year={1990}
}

@article{winograd1980does,
  title={What does it mean to understand language?},
  author={Winograd, Terry},
  journal={Cognitive science},
  volume={4},
  number={3},
  pages={209--241},
  year={1980},
  publisher={No longer published by Elsevier}
}

@article{higashino1986knowledge,
  title={A knowledge-based segmentation method for document understanding},
  author={Higashino, Jun'ichi and Fujisawa, Hiromichi and Nakano, Yasuaki and Ejiri, Masakazu},
  journal={space},
  volume={50},
  number={60},
  pages={10},
  year={1986}
}

@article{govindan1990character,
  title={Character recognition—a review},
  author={Govindan, VK and Shivaprasad, AP},
  journal={Pattern recognition},
  volume={23},
  number={7},
  pages={671--683},
  year={1990},
  publisher={Elsevier}
}
%######################################################     Compilers       ############################################
@phdthesis{Theroy_compiler,
  title={Digital computers. On encoding logical-mathematical formulas using the machine itself during program conception},
  author={B{\"o}hm, CORRADO},
  year={2016},
  school={Doctoral dissertation, ETH Z{\"u}rich 1954. http://www. itu. dk/people/sestoft~…}
}

@article{Grace_Murray_Hopper_History,
  title={The Mathematics of Grace Murray Hopper},
  author={Auel, Asher},
  journal={Notices of the American Mathematical Society},
  volume={66},
  number={3},
  year={2019}
}
%######################################################     OCR     ####################################################
@inproceedings{AnOverviewoftheTesseractOCREngine,
  title={An overview of the Tesseract OCR engine},
  author={Smith, Ray},
  booktitle={Ninth international conference on document analysis and recognition (ICDAR 2007)},
  volume={2},
  pages={629--633},
  year={2007},
  organization={IEEE}
}

@techreport{UNLV_4th_annual_test_ocr,
  title={The fourth annual test of OCR accuracy},
  author={Rice, Stephen V and Jenkins, Frank R and Nartker, Thomas A},
  year={1995},
  institution={Technical Report 95}
}

@inproceedings{Line_Finding_Algorithem,
  title={A simple and efficient skew detection algorithm via text row accumulation},
  author={Smith, Ray},
  booktitle={Proceedings of 3rd International Conference on Document Analysis and Recognition},
  volume={2},
  pages={1145--1148},
  year={1995},
  organization={IEEE}
}

@book{least_median_squares_algorithm,
  title={Robust regression and outlier detection},
  author={Rousseeuw, Peter J and Leroy, Annick M},
  year={2005},
  publisher={John wiley \& sons}
}

@article{quadratic_spline_algorithm,
  title={Imaging Defects},
  author={Rice, Stephen V and Nagy, George and Nartker, Thomas A and Rice, Stephen V and Nagy, George and Nartker, Thomas A},
  journal={Optical Character Recognition: An Illustrated Guide to the Frontier},
  pages={7--60},
  year={1999},
  publisher={Springer}
}

@article{Traditional_cubic_algorithm,
  title={An algorithm for automatically fitting digitized curves},
  author={Schneider, Philip J},
  journal={Graphics gems},
  pages={612--626},
  year={1990},
  publisher={Elsevier}
}


%###################################################    Machine Translation     ########################################################

@article{robert1957review,
  title={Review od syntactic structures},
  author={Robert, Lees},
  journal={Language},
  volume={33},
  number={3},
  pages={375--408},
  year={1957}
}

@inproceedings{tokenization_history,
  title={A conceptual dependency parser for natural language},
  author={Schank, Roger C and Tesler, Larry},
  booktitle={International Conference on Computational Linguistics COLING 1969: Preprint No. 2},
  year={1969}
}


%###################################################        Transformers            ##############################################################
@article{wolf2019huggingface,
  title={Huggingface's transformers: State-of-the-art natural language processing},
  author={Wolf, Thomas and Debut, Lysandre and Sanh, Victor and Chaumond, Julien and Delangue, Clement and Moi, Anthony and Cistac, Pierric and Rault, Tim and Louf, R{\'e}mi and Funtowicz, Morgan and others},
  journal={arXiv preprint arXiv:1910.03771                                            }      ,
  year={2019}
}

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{GPT_2,
  title={Language models are unsupervised multitask learners},
  author={Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya and others},
  journal={OpenAI blog},
  volume={1},
  number={8},
  pages={9},
  year={2019}
}

@article{DistilBERT,
  title={DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter},
  author={Sanh, Victor and Debut, Lysandre and Chaumond, Julien and Wolf, Thomas},
  journal={arXiv preprint arXiv:1910.01108        }    ,
  year={2019}
}


%--------------------------------------------------------------------------          previous methods and tasks     
@article{cheng2016longshorttermmemory,
  title={Long short-term memory-networks for machine reading},
  author={Cheng, Jianpeng and Dong, Li and Lapata, Mirella},
  journal={arXiv preprint arXiv:1601.06733                                                  }   ,
  year={2016}
}

@article{parikh2016decomposable,
  title={A decomposable attention model for natural language inference},
  author={Parikh, Ankur P and T{\"a}ckstr{\"o}m, Oscar and Das, Dipanjan and Uszkoreit, Jakob},
  journal={arXiv preprint arXiv:1606.01933                                                    }   ,
  year={2016}
}

@article{paulus2017deep,
  title={A deep reinforced model for abstractive summarization},
  author={Paulus, Romain and Xiong, Caiming and Socher, Richard},
  journal={arXiv preprint arXiv:1705.04304                                                       }   ,
  year={2017}
}

@article{lin2017structured,
  title={A structured self-attentive sentence embedding},
  author={Lin, Zhouhan and Feng, Minwei and Santos, Cicero Nogueira dos and Yu, Mo and Xiang, Bing and Zhou, Bowen and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1703.03130                                                       }   ,
  year={2017}
}

@article{sukhbaatar2015end,
  title={End-to-end memory networks},
  author={Sukhbaatar, Sainbayar and Weston, Jason and Fergus, Rob and others},
  journal={Advances in neural information processing systems},
  volume={28},
  year={2015}
}


%------------------------------------------------     Architecture --------------------------
@article{graves2013generating,
  title={Generating sequences with recurrent neural networks},
  author={Graves, Alex},
  journal={arXiv preprint arXiv:1308.0850                                                  } ,
  year={2013}
}

@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}

@article{ba2016layer,
  title={Layer normalization},
  author={Ba, Jimmy Lei and Kiros, Jamie Ryan and Hinton, Geoffrey E},
  journal={arXiv preprint arXiv:1607.06450        }                                          ,
  year={2016}
}
%------------------------------------------------     Residual connections
@misc{Residual_connection,
  title        = {Huggingface},
  author       = {Huggingface},
  year         = 2024,
  note         = {Accessed: (19.03.2024)},
  howpublished = {\url{https://towardsdatascience.com/what-is-residual-connection-efb07cab0d55}}
}
%-------------------------------------------------- Feed Forward
@article{ReLU,
  title={Deep learning using rectified linear units (relu)},
  author={Agarap, Abien Fred},
  journal={arXiv preprint arXiv:1803.08375  }                               ,
  year={2018}
}

@article{tanh,
  title={Extended tanh-function method and its applications to nonlinear equations},
  author={Fan, Engui},
  journal={Physics Letters A},
  volume={277},
  number={4-5},
  pages={212--218},
  year={2000},
  publisher={Elsevier}
}


%####################################################################       Pre-Training and Fine-Tunning
@article{Transfer_learning,
  title={A maximum likelihood approach to continuous speech recognition},
  author={Bahl, Lalit R and Jelinek, Frederick and Mercer, Robert L},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  pages={179--190},
  year={1983},
  publisher={IEEE}
}


@article{radford2018improving,
  title={Improving language understanding by generative pre-training},
  author={Radford, Alec and Narasimhan, Karthik and Salimans, Tim and Sutskever, Ilya and others},
  year={2018},
  journal= {\url{https://www.mikecaptain.com/resources/pdf/GPT-1.pdf}},
  publisher={OpenAI}
}



@article{T5,
  title={Exploring the limits of transfer learning with a unified text-to-text transformer},
  author={Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J},
  journal={The Journal of Machine Learning Research},
  volume={21},
  number={1},
  pages={5485--5551},
  year={2020},
  publisher={JMLRORG}
}




%###########################################  Cloud Computing ###################################
@article{lee2013view,
  title={A view of cloud computing},
  author={Lee, Juhnyoung},
  journal={International Journal of Networked and Distributed Computing},
  volume={1},
  number={1},
  pages={2--8},
  year={2013},
  publisher={Springer}
}

@misc{AWS_ec2,
    author = {Amazon EC2},
    title = {Amazon  Elastic Computing cloud},
    howpublished  = {\url{https://aws.amazon.com/pm/ec2/}},
}
%--------------------------------------------- ML on Cloud ----------------------
@article{google_tpu,
  title={Motivation for and evaluation of the first tensor processing unit},
  author={Jouppi, Norman and Young, Cliff and Patil, Nishant and Patterson, David},
  journal={ieee Micro},
  volume={38},
  number={3},
  pages={10--19},
  year={2018},
  publisher={IEEE}
}

@misc{Googlecloud,
    author = {Google},
    title = {Google Cloud},
    howpublished  = {\url{https://cloud.google.com/?hl=en}},
}

@misc{Nvidiagpu,
    author = {NVIDIA},
    title = {NVIDIA H100 Tensor Core GPU},
    howpublished  = {\url{https://www.nvidia.com/en-us/data-center/h100/}},
}

@misc{huggingfacehub,
  title        = {Huggingface},
  author       = {Huggingface},
  year         = 2024,
  note         = {Accessed: (13.03.2024)},
  howpublished = {\url{https://huggingface.co/}}
}

%##########################################################################################################################################################################################################################     Literature review       ########################################################################################################

@inproceedings{kieninger1998paper,
  title={A paper-to-HTML table converting system},
  author={Kieninger, Thomas and Dengel, Andreas},
  booktitle={Proceedings of document analysis systems (DAS)},
  volume={98},
  pages={356--365},
  year={1998}
}

@inproceedings{hao2016table,
  title={A table detection method for pdf documents based on convolutional neural networks},
  author={Hao, Leipeng and Gao, Liangcai and Yi, Xiaohan and Tang, Zhi},
  booktitle={2016 12th IAPR Workshop on Document Analysis Systems (DAS)},
  pages={287--292},
  year={2016},
  organization={IEEE}
}

@inproceedings{xu2020layoutlm,
  title={Layoutlm: Pre-training of text and layout for document image understanding},
  author={Xu, Yiheng and Li, Minghao and Cui, Lei and Huang, Shaohan and Wei, Furu and Zhou, Ming},
  booktitle={Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery \& Data Mining},
  pages={1192--1200},
  year={2020}
}


@article{ren2015faster,
  title={Faster r-cnn: Towards real-time object detection with region proposal networks},
  author={Ren, Shaoqing and He, Kaiming and Girshick, Ross and Sun, Jian},
  journal={Advances in neural information processing systems},
  volume={28},
  year={2015}
}

@inproceedings{he2017mask,
  title={Mask r-cnn},
  author={He, Kaiming and Gkioxari, Georgia and Doll{\'a}r, Piotr and Girshick, Ross},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={2961--2969},
  year={2017}
}

@inproceedings{yang2017learning,
  title={Learning to extract semantic structure from documents using multimodal fully convolutional neural networks},
  author={Yang, Xiao and Yumer, Ersin and Asente, Paul and Kraley, Mike and Kifer, Daniel and Lee Giles, C},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={5315--5324},
  year={2017}
}

@article{xu2021layoutxlm,
  title={Layoutxlm: Multimodal pre-training for multilingual visually-rich document understanding},
  author={Xu, Yiheng and Lv, Tengchao and Cui, Lei and Wang, Guoxin and Lu, Yijuan and Florencio, Dinei and Zhang, Cha and Wei, Furu},
  journal={arXiv preprint arXiv:2104.08836                               } ,
  year={2021}
}

%------------------------------------------  Differenet document understanding task citations

@inproceedings{jaume2019funsd,
  title={Funsd: A dataset for form understanding in noisy scanned documents},
  author={Jaume, Guillaume and Ekenel, Hazim Kemal and Thiran, Jean-Philippe},
  booktitle={2019 International Conference on Document Analysis and Recognition Workshops (ICDARW)},
  volume={2},
  pages={1--6},
  year={2019},
  organization={IEEE}
}

@article{gralinski2020kleister,
  title={Kleister: A novel task for information extraction involving long documents with complex layout},
  author={Grali{\'n}ski, Filip and Stanis{\l}awek, Tomasz and Wr{\'o}blewska, Anna and Lipi{\'n}ski, Dawid and Kaliska, Agnieszka and Rosalska, Paulina and Topolski, Bartosz and Biecek, Przemys{\l}aw},
  journal={arXiv preprint arXiv:2003.02356                            }   ,
  year={2020}
}

@inproceedings{mathew2021docvqa,
  title={Docvqa: A dataset for vqa on document images},
  author={Mathew, Minesh and Karatzas, Dimosthenis and Jawahar, CV},
  booktitle={Proceedings of the IEEE/CVF winter conference on applications of computer vision},
  pages={2200--2209},
  year={2021},
}


@article{devlin2018bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805                              } ,
  year={2018},
}

@article{lample2019cross,
  title={Cross-lingual language model pretraining},
  author={Lample, Guillaume and Conneau, Alexis},
  journal={arXiv preprint arXiv:1901.07291                                 } ,
  year={2019}
} 

@article{xue2020mt5,
  title={mT5: A massively multilingual pre-trained text-to-text transformer},
  author={Xue, Linting and Constant, Noah and Roberts, Adam and Kale, Mihir and Al-Rfou, Rami and Siddhant, Aditya and Barua, Aditya and Raffel, Colin},
  journal={arXiv preprint arXiv:2010.11934                                  },
  year={2020}
}

@inproceedings{lewis2006building,
  title={Building a test collection for complex document information processing},
  author={Lewis, David and Agam, Gady and Argamon, Shlomo and Frieder, Ophir and Grossman, David and Heard, Jefferson},
  booktitle={Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval},
  pages={665--666},
  year={2006}
}

%####################################################################      Deployment       ########################################################################################################

@misc{analytics2019global,
  title={Global AI Survey: AI proves its worth, but few scale impact},
  author={Analytics, McKinsey},
  year={2019}
}

@article{paleyes2022challenges,
  title={Challenges in deploying machine learning: a survey of case studies},
  author={Paleyes, Andrei and Urma, Raoul-Gabriel and Lawrence, Neil D},
  journal={ACM computing surveys},
  volume={55},
  number={6},
  pages={1--29},
  year={2022},
  publisher={ACM New York, NY}
}

@article{ashmore2021assuring,
  title={Assuring the machine learning lifecycle: Desiderata, methods, and challenges},
  author={Ashmore, Rob and Calinescu, Radu and Paterson, Colin},
  journal={ACM Computing Surveys (CSUR)},
  volume={54},
  number={5},
  pages={1--39},
  year={2021},
  publisher={ACM New York, NY, USA}
}

@article{wiggers2019algorithmia,
  title={Algorithmia: 50\% of companies spend between 8 and 90 days deploying a single AI model},
  author={Wiggers, Kyle},
  journal={The Machine: Making Sense of AI},
  year={2019}
}

@article{hecht2019add,
  title={Add it up: How long does a machine learning deployment take},
  author={Hecht, Lawrence E},
  journal={The New Stack. TheNewStack},
  volume={12},
  year={2019}
}

@article{wiggers2019idc,
  title={IDC: For 1 in 4 companies, half of all AI projects fail, 2019},
  author={Wiggers, Kyle},
  journal={Retrieved Oct},
  volume={14},
  pages={2022},
  year={2019}
}

@article{shearer2000crisp,
  title={The CRISP-DM model: the new blueprint for data mining},
  author={Shearer, Colin},
  journal={Journal of data warehousing},
  volume={5},
  number={4},
  pages={13--22},
  year={2000},
  publisher={THE DATA WAREHOUSE INSTITUTE}
}

@misc{TDSP,
  title        = {Team Data Science Process},
  author       = {Microsoft},
  year         = 2016,
  note         = {Accessed: (22.03.2024)},
  howpublished = {\url{https://learn.microsoft.com/en-us/azure/architecture/data-science-process/overview}}
}

@inproceedings{dang2019aiops,
  title={Aiops: real-world challenges and research innovations},
  author={Dang, Yingnong and Lin, Qingwei and Huang, Peng},
  booktitle={2019 IEEE/ACM 41st International Conference on Software Engineering: Companion Proceedings (ICSE-Companion)},
  pages={4--5},
  year={2019},
  organization={IEEE}
}

@misc{Sagemaker,
  title        = {SageMaker},
  author       = {Amazon Web Services},
  note         = {Accessed: (22.03.2024)},
  howpublished = {\url{https://aws.amazon.com/sagemaker/}}
}

@misc{AzureML,
  title        = {Azure Machine Learning},
  author       = {Microsoft},
  note         = {Accessed: (22.03.2024)},
  howpublished = {\url{https://azure.microsoft.com/en-us/products/machine-learning}}
}

@misc{TFX,
  title        = {TFX},
  author       = {Tensorflow},
  note         = {Accessed: (22.03.2024)},
  howpublished = {\url{https://www.tensorflow.org/tfx}}
}

@misc{mlflow,
  title        = {MLflow},
  author       = {mlflow},
  note         = {Accessed: (22.03.2024)},
  howpublished = {\url{https://mlflow.org/#core-concepts}}
}

@article{ribeiro2020beyond,
  title={Beyond accuracy: Behavioral testing of NLP models with CheckList},
  author={Ribeiro, Marco Tulio and Wu, Tongshuang and Guestrin, Carlos and Singh, Sameer},
  journal={arXiv preprint arXiv:2005.04118}                   ,
  year={2020}
}

@inproceedings{hynes2017data,
  title={The data linter: Lightweight, automated sanity checking for ml data sets},
  author={Hynes, Nick and Sculley, D and Terry, Michael},
  booktitle={NIPS MLSys Workshop},
  volume={1},
  year={2017}
}

@article{ebert2016devops,
  title={DevOps},
  author={Ebert, Christof and Gallardo, Gorka and Hernantes, Josune and Serrano, Nicolas},
  journal={IEEE software},
  volume={33},
  number={3},
  pages={94--100},
  year={2016},
  publisher={Ieee}
}

%#################################################################################################################################################################################          METHODS : 
%--------------------------------------------Proposed Model



@article{liu2019roberta,
  title={Roberta: A robustly optimized bert pretraining approach},
  author={Liu, Yinhan and Ott, Myle and Goyal, Naman and Du, Jingfei and Joshi, Mandar and Chen, Danqi and Levy, Omer and Lewis, Mike and Zettlemoyer, Luke and Stoyanov, Veselin},
  journal={arXiv preprint arXiv:1907.11692                  }     ,
  year={2019}
}

@article{chi2020infoxlm,
  title={InfoXLM: An information-theoretic framework for cross-lingual language model pre-training},
  author={Chi, Zewen and Dong, Li and Wei, Furu and Yang, Nan and Singhal, Saksham and Wang, Wenhui and Song, Xia and Mao, Xian-Ling and Huang, Heyan and Zhou, Ming},
  journal={arXiv preprint arXiv:2007.07834                    }   ,
  year={2020}
}

@article{loshchilov2017decoupled,
  title={Decoupled weight decay regularization},
  author={Loshchilov, Ilya and Hutter, Frank},
  journal={arXiv preprint arXiv:1711.05101                    }  ,
  year={2017}
}

@article{yu2020fine,
  title={Fine-tuning pre-trained language model with weak supervision: A contrastive-regularized self-training approach},
  author={Yu, Yue and Zuo, Simiao and Jiang, Haoming and Ren, Wendi and Zhao, Tuo and Zhang, Chao},
  journal={arXiv preprint arXiv:2010.07835                     } ,
  year={2020}
}

%------------------------------------------------ Tokenization

@book{faber2012constructing,
  title={Constructing a lexicon of English verbs},
  author={Faber, Pamela B and Us{\'o}n, Ricardo Mairal},
  volume={23},
  year={2012},
  publisher={Walter de Gruyter}
}

@book{manning2008introduction,
  title={Introduction to information retrieval},
  author={Manning, Christopher D and Raghavan, Prabhakar and Sch{\"u}tze, Hinrich},
  year={2008},
  publisher={Cambridge university press}
}

@inproceedings{schuster2012japanese,
  title={Japanese and korean voice search},
  author={Schuster, Mike and Nakajima, Kaisuke},
  booktitle={2012 IEEE international conference on acoustics, speech and signal processing (ICASSP)},
  pages={5149--5152},
  year={2012},
  organization={IEEE}
}

@article{wu2016google,
  title={Google's neural machine translation system: Bridging the gap between human and machine translation},
  author={Wu, Yonghui and Schuster, Mike and Chen, Zhifeng and Le, Quoc V and Norouzi, Mohammad and Macherey, Wolfgang and Krikun, Maxim and Cao, Yuan and Gao, Qin and Macherey, Klaus and others},
  journal={arXiv preprint arXiv:1609.08144 } ,
  year={2016}
}

%---------------------------------------------------------      Datasets
@inproceedings{park2019cord,
  title={CORD: a consolidated receipt dataset for post-OCR parsing},
  author={Park, Seunghyun and Shin, Seung and Lee, Bado and Lee, Junyeop and Surh, Jaeheung and Seo, Minjoon and Lee, Hwalsuk},
  booktitle={Workshop on Document Intelligence at NeurIPS 2019},
  year={2019}
}

@article{schmidt2002building,
  title={Building digital tobacco industry document libraries at the university of california, san francisco library/center for knowledge management},
  author={Schmidt, Heidi and Butter, Karen and Rider, Cynthia},
  journal={D-Lib Magazine},
  volume={8},
  number={9},
  pages={1082--9873},
  year={2002}
}

@inproceedings{xfund,
    title = "{XFUND}: A Benchmark Dataset for Multilingual Visually Rich Form Understanding",
    author = "Xu, Yiheng  and
      Lv, Tengchao  and
      Cui, Lei  and
      Wang, Guoxin  and
      Lu, Yijuan  and
      Florencio, Dinei  and
      Zhang, Cha  and
      Wei, Furu",
    booktitle = "Findings of the Association for Computational Linguistics: ACL 2022",
    month = may,
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.findings-acl.253",
    doi = "10.18653/v1/2022.findings-acl.253",
    pages = "3214--3224",
    abstract = "Multimodal pre-training with text, layout, and image has achieved SOTA performance for visually rich document understanding tasks recently, which demonstrates the great potential for joint learning across different modalities. However, the existed research work has focused only on the English domain while neglecting the importance of multilingual generalization. In this paper, we introduce a human-annotated multilingual form understanding benchmark dataset named XFUND, which includes form understanding samples in 7 languages (Chinese, Japanese, Spanish, French, Italian, German, Portuguese). Meanwhile, we present LayoutXLM, a multimodal pre-trained model for multilingual document understanding, which aims to bridge the language barriers for visually rich document understanding. Experimental results show that the LayoutXLM model has significantly outperformed the existing SOTA cross-lingual pre-trained models on the XFUND dataset. The XFUND dataset and the pre-trained LayoutXLM model have been publicly available at https://aka.ms/layoutxlm.",
}

@article{li2021cross,
  title={Cross-lingual named entity recognition using parallel corpus: A new approach using xlm-roberta alignment},
  author={Li, Bing and He, Yujie and Xu, Wenjin},
  journal={arXiv preprint arXiv:2101.11112}    ,
  year={2021}
}

@inproceedings{harley2015evaluation,
  title={Evaluation of deep convolutional nets for document image classification and retrieval},
  author={Harley, Adam W and Ufkes, Alex and Derpanis, Konstantinos G},
  booktitle={2015 13th International Conference on Document Analysis and Recognition (ICDAR)},
  pages={991--995},
  year={2015},
  organization={IEEE}
}